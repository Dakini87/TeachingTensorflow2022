{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f2f2dc2",
   "metadata": {},
   "source": [
    "# Using TensorBoard to track metrics, images, audio and text\n",
    "\n",
    "In this notebook we show how to use the TensorBoard extension which allows to keep track of training runs and data associated with each epoch (e.g. loss, accuracies, predicted/generated outputs, activation statistics etc.)\n",
    "\n",
    "First we will look at tensorflow's summary writer and what it can (and should) be used for. In a separate notebook, we will look at an example of how this can be used inside a subclassed model to keep track of the training and validation loss, as well as accuracies, also using keras metrics.\n",
    "\n",
    "The summary writer can be used to log scalars, feature maps (e.g. batches of generated images or activations), histograms, audio (batches of 1D sequences), and text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd0daa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b53f7ab",
   "metadata": {},
   "source": [
    "We start by loading the tensorboard extension. This only applies if you're using a notebook and want to show the tensorboard inside the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56c2e99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4402d1a5",
   "metadata": {},
   "source": [
    "For the sake of demonstration, we iterate over 100 steps and try to store a loss, some randomly generated images, an audio tensor, text, and a histogram for each step. We do not yet use a deep learning model, we only show the code necessary to store different kinds of data to log files that can be read by the TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a1b8899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define file-path for log file\n",
    "file_path = \"test_logs/test\"\n",
    "\n",
    "# define the tf file-writer (we usually use a separate one for train and validation)\n",
    "summary_writer = tf.summary.create_file_writer(file_path)\n",
    "\n",
    "loss_function = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "# write 100 logs for loss\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    # CREATE DATA OF DIFFERENT KINDS\n",
    "    \n",
    "    # compute loss (here targets and predictions would come from the data and the model)\n",
    "    targets = tf.constant([0.3,0.3,-0.8])\n",
    "    predictions = targets + tf.random.normal(shape=targets.shape, stddev=100/(i+1)) # decreasing noise\n",
    "    loss = loss_function(targets,predictions)\n",
    "    \n",
    "    # image batch (these would be obtained from the model)\n",
    "    image_batch = tf.random.uniform(shape=(32,28,28,1),dtype=tf.float32)\n",
    "    \n",
    "    # audio batch (would be obtained from the model but here it's just a hard coded sine wave of 110hz)\n",
    "    x = 2* math.pi*tf.cast(tf.linspace(0,32000*5, 32000*5), tf.float32)*110/32000\n",
    "    x = tf.expand_dims(x, axis=0) # add batch dimension\n",
    "    x = tf.expand_dims(x, axis=-1) # add last dimension\n",
    "    x = tf.repeat(x, 32, axis=0) # repeat to have a batch of 32\n",
    "    audio_batch = tf.math.sin(x) # obtain sine wave\n",
    "    \n",
    "    # text (this would be the output of a language model after one training epoch)\n",
    "    text = tf.constant(\"This is the sampled output of a language model\")\n",
    "    \n",
    "    # histogram (e.g. of activations of a dense layer during training)\n",
    "    activations_batch = tf.random.normal(shape=(32,20,1))\n",
    "    #in_activations = tf.reduce_min(activations_batch, axis=None)\n",
    "    #max_activations = tf.reduce_max(activations_batch, axis=None)\n",
    "    #histogram = tf.histogram_fixed_width_bins(activations_batch, \n",
    "    #                                          value_range=[min_activations, max_activations])\n",
    "    histogram = activations_batch #tf.reduce_mean(activations_batch,axis=\n",
    "    # WRITE THE DATA TO A LOG FILE USING A SUMMARY WRITER\n",
    "    with summary_writer.as_default():\n",
    "        \n",
    "        # save the loss scalar for the \"epoch\"\n",
    "        tf.summary.scalar(name=\"loss\", data=loss, step=i)\n",
    "        \n",
    "        # save a batch of images for this epoch (have to be between 0 and 1)\n",
    "        tf.summary.image(name=\"generated_images\",data = image_batch, step=i, max_outputs=32)\n",
    "        \n",
    "        # save the batch of audio for this epoch\n",
    "        tf.summary.audio(name=\"generated_audio\", data = audio_batch, \n",
    "                         sample_rate = 32000, step=i, max_outputs=32)\n",
    "        \n",
    "        # save the generated text for that epoch\n",
    "        tf.summary.text(name=\"generated_text\", data = text, step=i)\n",
    "        \n",
    "        # save a histogram (e.g. of activations in a layer)\n",
    "        tf.summary.histogram(name=\"layer_N_activations\", data = activations_batch, step=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e422c5",
   "metadata": {},
   "source": [
    "# Inspect the logged data in the TensorBoard\n",
    "\n",
    "We can look at the images, audio, text, histograms and plots for each time-step. \n",
    "\n",
    "For plots under the \"scalars\" section, we can control the amount of smoothing for the plots. This allows us to visually judge whether the loss is decreasing even in the presence of strong oscillations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8568d249",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Open the tensorboard\n",
    "\n",
    "- If you're not using a notebook, activate your environment in your terminal and type tensorboard --logdir test_logs/ where test_logs is the folder that contains the logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82f2ed55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 21473), started 2:08:56 ago. (Use '!kill 21473' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b9f489eb311225a8\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b9f489eb311225a8\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir test_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fb526c",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "- We can keep track of many things and analyze them already while a model is still training.\n",
    "\n",
    "- We can save activations and also gradients during training as images or histograms, which can be super helpful for debugging!\n",
    "\n",
    "- We can monitor model performance either quantitatively using scalar measures or qualitatively by logging predictions (image outputs, audio outputs or text outputs)\n",
    "\n",
    "\n",
    "Next: **Full training loop**, using Tensorboard with the model class incl. keras metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "54ff86533a6a943eb33cb0954e5964c6e356fb8134919fff31cf4713965c9c7c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
